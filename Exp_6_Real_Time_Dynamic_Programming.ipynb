{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5D1oSpRcgWk",
        "outputId": "fc27feab-8da9-44cf-85aa-13b980cb6fd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Value Function:\n",
            "[[ -9.74968445  -9.81751996 -10.          -9.99999088  -7.45813417]\n",
            " [ -9.93637315   0.          -9.0152291   -9.99915359  -8.78423345]\n",
            " [ -9.99140496  -8.49905365   0.          -8.78423345  -4.0951    ]\n",
            " [ -9.81751996  -9.52898713  -1.9          0.           0.        ]\n",
            " [ -4.0951      -6.5132156   -1.           0.           0.        ]]\n",
            "Policy:\n",
            "v < < > v \n",
            "v X > v v \n",
            "v < X > v \n",
            "v > v X v \n",
            "> ^ > > G \n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "class GridWorld:\n",
        "    def __init__(self, width, height, start, goal, obstacles):\n",
        "        self.width = width\n",
        "        self.height = height\n",
        "        self.start = start\n",
        "        self.goal = goal\n",
        "        self.obstacles = obstacles\n",
        "        self.grid = np.zeros((height, width))\n",
        "        for obstacle in obstacles:\n",
        "            self.grid[obstacle] = -1  # Mark obstacles\n",
        "\n",
        "    def is_terminal(self, state):\n",
        "        return state == self.goal\n",
        "\n",
        "    def get_possible_actions(self, state):\n",
        "        actions = []\n",
        "        x, y = state\n",
        "        if x > 0 and self.grid[y, x-1] != -1:\n",
        "            actions.append((-1, 0))  # Left\n",
        "        if x < self.width - 1 and self.grid[y, x+1] != -1:\n",
        "            actions.append((1, 0))   # Right\n",
        "        if y > 0 and self.grid[y-1, x] != -1:\n",
        "            actions.append((0, -1))  # Up\n",
        "        if y < self.height - 1 and self.grid[y+1, x] != -1:\n",
        "            actions.append((0, 1))   # Down\n",
        "        return actions\n",
        "\n",
        "    def transition(self, state, action):\n",
        "        return (state[0] + action[0], state[1] + action[1])\n",
        "\n",
        "def rtdp(grid_world, max_trials=1000, discount_factor=0.9):\n",
        "    V = np.zeros((grid_world.height, grid_world.width))  # Value function\n",
        "    policy = np.full((grid_world.height, grid_world.width), None)  # Policy\n",
        "\n",
        "    for _ in range(max_trials):\n",
        "        state = grid_world.start\n",
        "        while not grid_world.is_terminal(state):\n",
        "            actions = grid_world.get_possible_actions(state)\n",
        "            if not actions:\n",
        "                break\n",
        "            action = random.choice(actions)\n",
        "            next_state = grid_world.transition(state, action)\n",
        "\n",
        "            # Reward mechanism\n",
        "            reward = 0 if next_state == grid_world.goal else -1\n",
        "\n",
        "            # Update value function\n",
        "            V[state[1], state[0]] = reward + discount_factor * V[next_state[1], next_state[0]]\n",
        "\n",
        "            # Update policy\n",
        "            policy[state[1], state[0]] = action\n",
        "            state = next_state\n",
        "\n",
        "    return V, policy\n",
        "\n",
        "def visualize_policy(grid_world, policy):\n",
        "    direction_map = {\n",
        "        (-1, 0): '<',\n",
        "        (1, 0): '>',\n",
        "        (0, -1): '^',\n",
        "        (0, 1): 'v'\n",
        "    }\n",
        "    for y in range(grid_world.height):\n",
        "        for x in range(grid_world.width):\n",
        "            if (x, y) in grid_world.obstacles:\n",
        "                print('X', end=' ')\n",
        "            elif (x, y) == grid_world.goal:\n",
        "                print('G', end=' ')\n",
        "            elif policy[y, x] is None:\n",
        "                print('.', end=' ')\n",
        "            else:\n",
        "                print(direction_map[policy[y, x]], end=' ')\n",
        "        print()\n",
        "\n",
        "# Example usage\n",
        "width, height = 5, 5\n",
        "start = (0, 0)\n",
        "goal = (4, 4)\n",
        "obstacles = [(1, 1), (2, 2), (3, 3)]\n",
        "grid_world = GridWorld(width, height, start, goal, obstacles)\n",
        "V, policy = rtdp(grid_world)\n",
        "print(\"Value Function:\")\n",
        "print(V)\n",
        "print(\"Policy:\")\n",
        "visualize_policy(grid_world, policy)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q9yJ6wr_c0Gh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}